{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUkmDiaZ9Yua",
        "outputId": "c8917808-e63c-4f1f-c986-63f4a95d3b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100%|██████████| 6.25M/6.25M [00:00<00:00, 53.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 352x640 17 persons, 10 cars, 3 buss, 3 trucks, 1 traffic light, 1 handbag, 388.0ms\n",
            "Speed: 17.0ms preprocess, 388.0ms inference, 33.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Processed /content/1603455628_744060.jpg:\n",
            "Saved bounding-box image to /content/1603455628_744060_yolo.jpg\n",
            "Saved data to /content/1603455628_744060_data.txt\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Загрузка модели YOLOv8\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Список цветов для различных классов\n",
        "colors = [\n",
        "    (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255),\n",
        "    (255, 0, 255), (192, 192, 192), (128, 128, 128), (128, 0, 0), (128, 128, 0),\n",
        "    (0, 128, 0), (128, 0, 128), (0, 128, 128), (0, 0, 128), (72, 61, 139),\n",
        "    (47, 79, 79), (47, 79, 47), (0, 206, 209), (148, 0, 211), (255, 20, 147)\n",
        "]\n",
        "\n",
        "def process_image(image_path):\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    results = model(image)[0]\n",
        "\n",
        "\n",
        "    image = results.orig_img\n",
        "    classes_names = results.names\n",
        "    classes = results.boxes.cls.cpu().numpy()\n",
        "    boxes = results.boxes.xyxy.cpu().numpy().astype(np.int32)\n",
        "\n",
        "\n",
        "    grouped_objects = {}\n",
        "\n",
        "\n",
        "    for class_id, box in zip(classes, boxes):\n",
        "        class_name = classes_names[int(class_id)]\n",
        "        color = colors[int(class_id) % len(colors)]\n",
        "        if class_name not in grouped_objects:\n",
        "            grouped_objects[class_name] = []\n",
        "        grouped_objects[class_name].append(box)\n",
        "\n",
        "\n",
        "        x1, y1, x2, y2 = box\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "\n",
        "    new_image_path = os.path.splitext(image_path)[0] + '_yolo' + os.path.splitext(image_path)[1]\n",
        "    cv2.imwrite(new_image_path, image)\n",
        "\n",
        "\n",
        "    text_file_path = os.path.splitext(image_path)[0] + '_data.txt'\n",
        "    with open(text_file_path, 'w') as f:\n",
        "        for class_name, details in grouped_objects.items():\n",
        "            f.write(f\"{class_name}:\\n\")\n",
        "            for detail in details:\n",
        "                f.write(f\"Coordinates: ({detail[0]}, {detail[1]}, {detail[2]}, {detail[3]})\\n\")\n",
        "\n",
        "    print(f\"Processed {image_path}:\")\n",
        "    print(f\"Saved bounding-box image to {new_image_path}\")\n",
        "    print(f\"Saved data to {text_file_path}\")\n",
        "\n",
        "\n",
        "process_image(r\"/content/1603455628_744060.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3dm_TAD-GZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}